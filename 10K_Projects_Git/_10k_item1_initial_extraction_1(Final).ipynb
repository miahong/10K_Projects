{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import requests\n",
    "import re\n",
    "import glob\n",
    "import os, sys\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import csv\n",
    "import time\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from bs4 import BeautifulSoup\n",
    "from sec_edgar_downloader import Downloader\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import shutil\n",
    "from data_preparation import download_to_item1, clean_ticker\n",
    "dl = Downloader(\"/home/hongzhuoqiao/10K_Projects/sec_filings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function save in the data_preparation.py\n",
    "# no need to run this cell\n",
    "# def clean_ticker(tic):\n",
    "    \n",
    "#     if re.match('\\w+[.]\\w+', str(tic)):\n",
    "#         if re.match('\\w+[.]\\d+', str(tic)):\n",
    "#             tic = ''.join([i for i in tic if not i.isdigit()])\n",
    "#             tic = ''.join([i for i in tic if not i is \".\"])    \n",
    "#         else:\n",
    "#             tic = ''.join([i for i in tic if not i is \".\"])\n",
    "\n",
    "#     if re.match('\\w+[.]', str(tic)):        \n",
    "#         tic = ''.join([i for i in tic if not i is \".\"]) \n",
    "#     return tic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cusip</th>\n      <th>tic</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000361105</td>\n      <td>AIR</td>\n      <td>AIR</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>000886309</td>\n      <td>ADCT.1</td>\n      <td>ADCT</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>001058205</td>\n      <td>IWKS</td>\n      <td>IWKS</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>020813101</td>\n      <td>ALO.2</td>\n      <td>ALO</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>02376R102</td>\n      <td>AAL</td>\n      <td>AAL</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        cusip     tic ticker\n0   000361105     AIR    AIR\n13  000886309  ADCT.1   ADCT\n17  001058205    IWKS   IWKS\n19  020813101   ALO.2    ALO\n20  02376R102     AAL    AAL"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_df = pd.read_csv(\"/home/hongzhuoqiao/10K_Projects/sec_filings/multiple_observations.txt\", sep='\\t')\n",
    "tc_df = company_df[['cusip','tic']].drop_duplicates()\n",
    "tc_df['ticker'] = tc_df['tic'].apply(clean_ticker)\n",
    "tc_df.to_csv(\"/home/hongzhuoqiao/10K_Projects/sec_filings/tc.csv\")\n",
    "tc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## main function of extraction items for all companies\n",
    "## syncrynized with single_company_item1_extraction.ipynb\n",
    "## function save in the data_preparation.py\n",
    "## no need to run this cell\n",
    "def download_to_item1(ticker):\n",
    "    # file_number = dl.get(\"10-K\", ticker)\n",
    "    # print ('>>> Got {} for {}'.format(file_number, ticker))\n",
    "    error = 0\n",
    "    count = 1\n",
    "    extract_failed_flag = 0\n",
    "    error_file_list = []\n",
    "\n",
    "    if file_number:\n",
    "\n",
    "        path_header = \"/home/hongzhuoqiao/10K_Projects/sec_filings/sec_edgar_filings\"\n",
    "        path_for_extraction_item1 = path_header + \"/\" + ticker + \"/10-K\" +\"/*.txt\"\n",
    "        path_for_item1_folder = \"/home/hongzhuoqiao/10K_Projects/sec_filings/item1_section/\" + ticker\n",
    "        if not os.path.exists(path_for_item1_folder):\n",
    "            os.makedirs(path_for_item1_folder)\n",
    "            print (\">>> Created new folder for {}\".format(ticker))\n",
    "        else:\n",
    "            print (\">>> {} folder is already exists.\".format(ticker))\n",
    "\n",
    "        print (\">>> Start extracting item1 sections for {}\".format(ticker))\n",
    "    \n",
    "        files = glob.glob(path_for_extraction_item1)\n",
    "\n",
    "        # extract annual file for one company, loop every year in one company\n",
    "       \n",
    "        for file in files:\n",
    "            f = open(file, 'r')\n",
    "            print(\" \\n\\n>>>Starting open files {} for {}\".format(count, ticker))\n",
    "            filename = os.path.basename(file)\n",
    "            print (\">>> the file to be extracted is {}\\n\".format(filename))\n",
    "            newname_suffix = filename[10:13]\n",
    "            file_name = ticker+newname_suffix\n",
    "            \n",
    "            raw_10k = f.read()    \n",
    "            ######\n",
    "            # Regex to find <DOCUMENT> tags\n",
    "        \n",
    "            doc_start_pattern = re.compile(r'<DOCUMENT>')\n",
    "            doc_end_pattern = re.compile(r'</DOCUMENT>')\n",
    "            # Regex to find <TYPE> tag prceeding any characters, terminating at new line\n",
    "            type_pattern = re.compile(r'<TYPE>[^\\n]+')\n",
    "\n",
    "            ### as section names\n",
    "            doc_start_is = [x.end() for x in doc_start_pattern.finditer(raw_10k)]\n",
    "            doc_end_is = [x.start() for x in doc_end_pattern.finditer(raw_10k)]\n",
    "            doc_types = [x[len('<TYPE>'):] for x in type_pattern.findall(raw_10k)]\n",
    "\n",
    "            #regex = re.compile(r'(Item(\\s|&#160;|&nbsp;)(1A|1B|1|2)\\.{0,1})|(>Item(\\s|&#160;|&nbsp;)(1A|1B|1|2)\\.{0,1})|(ITEM(\\s|&#160;|&nbsp;)(1A|1B|1|2).{0,1})')\n",
    "\n",
    "            regex = re.compile(r'(Item(\\s|&#160;|&nbsp;)(1A|1B|1|2)\\.{0})|(>Item(\\s|&#160;|&nbsp;)(1A|1B|1|2)\\.{0})|(ITEM(\\s|&#160;|&nbsp;)(1A|1B|1|2)\\.{0})')\n",
    "\n",
    "            # Create a loop to go through each section type and save only the 10-K section in the dictionary\n",
    "            document = {}\n",
    "            doc = ''\n",
    "            for doc_type, doc_start, doc_end in zip(doc_types, doc_start_is, doc_end_is):\n",
    "                \n",
    "                if (doc_type =='10-K'):\n",
    "                    document[doc_type] = raw_10k[doc_start:doc_end]    \n",
    "                    # Use finditer to math the regex\n",
    "                    matches = regex.finditer(document['10-K'])\n",
    "                    doc = '10-K'                    \n",
    "                    # Write a for loop to print the matches                   \n",
    "                elif (doc_type =='10-K405'):\n",
    "                    document[doc_type] = raw_10k[doc_start:doc_end]    \n",
    "                    # Use finditer to math the regex\n",
    "                    matches = regex.finditer(document['10-K405'])\n",
    "                    doc = '10-K405'\n",
    "\n",
    "                elif (doc_type =='10-KT'):\n",
    "                    document[doc_type] = raw_10k[doc_start:doc_end]    \n",
    "                    # Use finditer to math the regex\n",
    "                    matches = regex.finditer(document['10-KT'])\n",
    "                    doc = '10-KT'\n",
    "\n",
    "            \n",
    "            # Create the dataframe\n",
    "            try:\n",
    "                matches = regex.finditer(document[doc])\n",
    "                test_df = pd.DataFrame([(x.group(), x.start(), x.end()) for x in matches])\n",
    "                test_df.columns = ['item', 'start', 'end']\n",
    "                test_df['item'] = test_df.item.str.lower()\n",
    "\n",
    "                # Get rid of unnesesary charcters from the dataframe\n",
    "                test_df.replace('&#160;',' ',regex=True,inplace=True)\n",
    "                test_df.replace('&nbsp;',' ',regex=True,inplace=True)\n",
    "                test_df.replace(' ','',regex=True,inplace=True)\n",
    "                test_df.replace('\\.','',regex=True,inplace=True)\n",
    "                test_df.replace('>','',regex=True,inplace=True)\n",
    "                test_df.replace('<','',regex=True,inplace=True)\n",
    "                test_df.replace('\\n','',regex=True,inplace=True)\n",
    "                # shift dataset to find the next, next next item\n",
    "                test_df['next_1'] = test_df['item'].shift(-1,fill_value=0)\n",
    "                test_df['next_1_start'] = test_df['start'].shift(-1,fill_value=0)\n",
    "                test_df['next_1_start'] = test_df.next_1_start.astype('int32')\n",
    "                # test_df['next_1_end'] = test_df['end'].shift(-1,fill_value=0)\n",
    "                # test_df['next_1_end'] = test_df.next_1_end.astype('int32')\n",
    "                test_df['pre_1'] = test_df['item'].shift(1,fill_value=0)\n",
    "                test_df['pre_1_start'] = test_df['start'].shift(1,fill_value=0)\n",
    "                test_df['pre_1_start'] = test_df.pre_1_start.astype('int32')    \n",
    "            \n",
    "            except:\n",
    "                error = error + 1\n",
    "                item_1_text = ''\n",
    "                error_file_list.append(filename[11:13])\n",
    "                extract_failed_flag = 1\n",
    "\n",
    "            if not extract_failed_flag:\n",
    "         \n",
    "                try:\n",
    "                    # doc contains 1a 1b section (newr files)\n",
    "                    if len(test_df[test_df['item'].str.contains('item1a')]):\n",
    "                        df = test_df[((test_df['item'] == 'item1') & (test_df['next_1'] == 'item1a'))|((test_df['item'] == 'item2') & (test_df['pre_1'] == 'item1b')) | ((test_df['item'] == 'item1') & (test_df['next_1'] == 'item2')) | ((test_df['item'] == 'item2') & (test_df['pre_1'] == 'item1a'))] \n",
    "                        df = df[['item', 'start', 'end']]\n",
    "                        df['next_item'] = df['item'].shift(-1,fill_value=0)\n",
    "                        df['next_item_start'] = df['start'].shift(-1,fill_value=0)\n",
    "                        df['next_item_start'] = df.next_item_start.astype('int32')\n",
    "                        df = df[(df['item']=='item1') & (df['next_item']=='item2')]\n",
    "                        df['difference'] = df['next_item_start'] - df['start']\n",
    "                        df.sort_values('difference', ascending = False, inplace = True)\n",
    "                        item_1_raw = document[doc][df.iloc[0]['start']:df.iloc[0]['next_item_start']]\n",
    "\n",
    "                    # doc no 1a 1b\n",
    "                    else:\n",
    "                        df_1 = test_df.sort_values('start', ascending=True).drop_duplicates(subset=['item'], keep='first')\n",
    "                        df_1.set_index('item', inplace=True)\n",
    "                        raw_1 = document[doc][df_1['start'].loc['item1']:df_1['start'].loc['item2']]\n",
    "                        \n",
    "                        df_2 = test_df[((test_df['item'] == 'item1') & (test_df['next_1'] == 'item2'))|((test_df['item'] == 'item2') & (test_df['pre_1'] == 'item1'))]\n",
    "                        df_2 = df_2[['item', 'start', 'end']]\n",
    "                        df_2['next_item'] = df_2['item'].shift(-1,fill_value=0)\n",
    "                        df_2['next_item_start'] = df_2['start'].shift(-1,fill_value=0)\n",
    "                        df_2['next_item_start'] = df_2.next_item_start.astype('int32')\n",
    "                        df_2 = df_2[(df_2['item']=='item1') & (df_2['next_item']=='item2')]\n",
    "                        df_2['difference'] = df_2['next_item_start'] - df_2['start']\n",
    "                        df_2 = df_2[(df_2['item']=='item1')& (df_2['start'] < 100000)]\n",
    "                        df_2.sort_values('difference', ascending = False, inplace = True)\n",
    "                        raw_2 = document[doc][df_2.iloc[0]['start']:df_2.iloc[0]['next_item_start']]\n",
    "\n",
    "                        if (len(raw_1)>=len(raw_2)):\n",
    "                            item_1_raw = raw_1\n",
    "                        else:\n",
    "                            item_1_raw = raw_2\n",
    "\n",
    "                    item_1_content = BeautifulSoup(item_1_raw, 'lxml')\n",
    "                    item_1_text = item_1_content.get_text()\n",
    "                    print(item_1_text[0:1000])\n",
    "\n",
    "                except:\n",
    "                    print (\"OPOOS!...Something Wrong!\")\n",
    "                    error = error + 1\n",
    "                    item_1_text = ''\n",
    "                    error_file_list.append(filename[11:13])\n",
    "\n",
    "\n",
    "                # path_for_item1_folder = \"/home/hongzhuoqiao/10K_Projects/sec_filings/item1_section/\" + ticker\n",
    "            new_file =open(path_for_item1_folder + \"/\" + file_name+\".txt\",\"a\")\n",
    "            new_file.write(item_1_text)\n",
    "        \n",
    "            print(\">>> New item1 new file for year {} is saved\\n\".format(file_name))\n",
    "            count = count + 1\n",
    "\n",
    "        try:\n",
    "            shutil.rmtree(\"/home/hongzhuoqiao/10K_Projects/sec_filings/sec_edgar_filings/\"+ticker)\n",
    "            print (\"{}'s folder has been deleted!\".format(ticker))\n",
    "        except OSError as e:\n",
    "            print(\"No folder to be deleted or errors in deleting folder.\")\n",
    "\n",
    "    else:\n",
    "        print ('>>> No 10k files for this company!')\n",
    "\n",
    "    return file_number, count-1, error,  error_file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "19827\n44\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cusip</th>\n      <th>tic</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>149645</th>\n      <td>46429B655</td>\n      <td>FLOT</td>\n      <td>FLOT</td>\n    </tr>\n    <tr>\n      <th>149654</th>\n      <td>025300104</td>\n      <td>CRYO</td>\n      <td>CRYO</td>\n    </tr>\n    <tr>\n      <th>149664</th>\n      <td>29355A107</td>\n      <td>ENPH</td>\n      <td>ENPH</td>\n    </tr>\n    <tr>\n      <th>149674</th>\n      <td>56502B100</td>\n      <td>MSO.UN</td>\n      <td>MSOUN</td>\n    </tr>\n    <tr>\n      <th>149676</th>\n      <td>74642Q101</td>\n      <td>FLOT.</td>\n      <td>FLOT</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            cusip     tic ticker\n149645  46429B655    FLOT   FLOT\n149654  025300104    CRYO   CRYO\n149664  29355A107    ENPH   ENPH\n149674  56502B100  MSO.UN  MSOUN\n149676  74642Q101   FLOT.   FLOT"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_1: 0:10\n",
    "# df_2: 10:20\n",
    "# df_3: 20:50\n",
    "# df_4: 50:100 \n",
    "# df_5: 100:200 \n",
    "# df_6: 200:500 \n",
    "# df_7: 500:1000 \n",
    "# df_8: 1000:2000 \n",
    "# df_9: 2000:2041 \n",
    "# df_10: 2043:2200 \n",
    "# df_11: 2200:3000  \n",
    "# df_12: 3000:3500 \n",
    "# df_13: 3500:4000 \n",
    "# df_14: 4000:5000 \n",
    "# df_15: 4000:5000 (repeated)\n",
    "# df_16: 5000:6000 \n",
    "# df_17: 6000:7000 \n",
    "# df_18: 7000:7100 \n",
    "# df_19: 7100:7500 \n",
    "# df_20: 7500:8000 \n",
    "# df_21: 8000:8500 \n",
    "# df_22: 8500:9000 \n",
    "# df_23: 9000:9500 \n",
    "# df_24: 9500:10000 \n",
    "# df_25: 10000:10500 \n",
    "# df_26: 10500:11000 \n",
    "# df_27: 11000:11500 \n",
    "# df_28: 11500:12000 \n",
    "# df_29: 12000:12500 \n",
    "# df_30: 12500:13000 \n",
    "# df_31: 13000:13500 \n",
    "# df_32: 13500:13825 skip 'VVI'  \n",
    "# df_33: 13826:14000 \n",
    "# df_34: 14000:14500 \n",
    "# df_35: 14500:15000\n",
    "# df_36: 15000:15500 \n",
    "# df_37: 15500:16000 \n",
    "# df_38: 16000:16500 \n",
    "# df_39: 16500:17000 \n",
    "# df_40: 17000:17500 \n",
    "# df_41: 17500:18000 \n",
    "# df_42: 18000:18500 \n",
    "# df_43: 18500:19000 \n",
    "# df_44: 19000: # current batch \n",
    "print (len(tc_df))\n",
    "print(\"44\")\n",
    "df_44 = tc_df[19000:]\n",
    "df_44.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error checking test cell\n",
    "# print(tc_df[tc_df['ticker']=='VVI'])\n",
    "# tc_df[13825:14000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "ices and systems, and we use our deep expertise to serve as trusted partners to end-users who seek customized solutions to their security needs. Allegion Principal ProductsDoor closers and controlsDoors and door systemsElectronic security productsElectronic, biometric and mobile access control systemsExit devicesLocks, locksets, portable locks, key systems and servicesTime, attendance and workforce productivity systemsOther accessoriesAc\n>>> New item1 new file for year ALLE-20 is saved\n\n \n\n>>>Starting open files 6 for ALLE\n>>> the file to be extracted is 0001579241-15-000005.txt\n\n>Item 1.    BUSINESSOverviewAllegion plc (\"Allegion,\" \"we,\" \"us\" or \"the Company\") is a leading global provider of security products and solutions that keep people safe, secure and productive. We make the world safer as a company of experts, securing the places where people thrive and we create peace of mind by pioneering safety and security. We offer an extensive and versatile portfolio of mechanical and electronic security products across a range of market-leading brands. Our experts across the globe deliver high-quality security products, services and systems and we use our deep expertise to serve as trusted partners to end-users who seek customized solutions to their security needs. Allegion Principal ProductsDoor closers and controlsDoor and door frames (steel)Electronic security productsElectronic and biometric access control systemsExit devicesLocks, locksets and key systemsTime, attendance and workforce productivity systemsVideo analytics systemsOther accessories Access control\n>>> New item1 new file for year ALLE-15 is saved\n\n \n\n>>>Starting open files 7 for ALLE\n>>> the file to be extracted is 0001579241-17-000009.txt\n\n>Item 1.    BUSINESSOverviewAllegion plc (\"Allegion,\" \"we,\" \"us\" or \"the Company\") is a leading global provider of security products and solutions that keep people safe, secure and productive. We make the world safer as a company of experts, securing the places where people thrive, and we create peace of mind by pioneering safety and security. We offer an extensive and versatile portfolio of mechanical and electronic security products across a range of market-leading brands. Our experts across the globe deliver high-quality security products, services and systems, and we use our deep expertise to serve as trusted partners to end-users who seek customized solutions to their security needs. Allegion Principal ProductsDoor closers and controlsDoor and door frames (steel)Electronic security productsElectronic and biometric access control systemsExit devicesLocks, locksets, portable locks and key systemsTime, attendance and workforce productivity systemsOther accessoriesAccess control secur\n>>> New item1 new file for year ALLE-17 is saved\n\nALLE's folder has been deleted!\n>>> Got 0 for AGHEF\n>>> No 10k files for this company!\n>>> Got 0 for PSV\n>>> No 10k files for this company!\n>>> Got 5 for LPG\n>>> Created new folder for LPG\n>>> Start extracting item1 sections for LPG\n \n\n>>>Starting open files 1 for LPG\n>>> the file to be extracted is 0001596993-17-000010.txt\n\nITEM 1.  BUSINESS  \n\t\t\n\n \n\n\nUnless otherwise indicated, references to \"Dorian,\" the \"Company,\" \"we,\" \"our,\" \"us,\" or similar terms refer to Dorian LPG Ltd. and its subsidiaries and predecessors. The terms \"Predecessor\" and \"Predecessor Business\" refer to the owning companies of the four vessels that comprised our initial fleet (hereinafter referred to as our \"Initial Fleet\"), prior to their acquisition by us.  We use the term \"VLGC\" to refer to very large gas carriers and the term “PGC” to refer to pressurized gas carriers. We use the term \"LPG\" to refer to liquefied petroleum gas and we use the term \"cbm\" to refer to cubic meters in describing the carrying capacity of our vessels. Unless otherwise indicated, all references to \"U.S. dollars,\" \"USD,\" \"dollars,\" and \"$\" in this report are to the lawful currency of the United States of America and references to \"Norwegian Krone\" and \"NOK\" are to the lawful currency of Norway. Unless stated otherwise, the information below gives effect to \n>>> New item1 new file for year LPG-17 is saved\n\n \n\n>>>Starting open files 2 for LPG\n>>> the file to be extracted is 0001596993-19-000010.txt\n\nITEM 1.  BUSINESS  \n\t\t\n\n \n\n\nUnless otherwise indicated, references to \"Dorian,\" the \"Company,\" \"we,\" \"our,\" \"us,\" or similar terms refer to Dorian LPG Ltd. and its subsidiaries and predecessors. The terms \"Predecessor\" and \"Predecessor Business\" refer to the owning companies of the four vessels that comprised our initial fleet, prior to their acquisition by us. We use the term \"VLGC\" to refer to very large gas carriers. We use the term \"LPG\" to refer to liquefied petroleum gas and we use the term \"cbm\" to refer to cubic meters in describing the carrying capacity of our vessels. Unless otherwise indicated, all references to \"U.S. dollars,\" \"USD,\" and \"$\" in this report are to the lawful currency of the United States of America and references to \"Norwegian Krone\" and \"NOK\" are to the lawful currency of Norway. \n\n\n \n\n\nOverview\n\n\n \n\n\nDorian was incorporated on July 1, 2013 under the laws of the Republic of the Marshall Islands, is headquartered in the United States and is engaged in the tr\n>>> New item1 new file for year LPG-19 is saved\n\n \n\n>>>Starting open files 3 for LPG\n>>> the file to be extracted is 0001596993-18-000015.txt\n\nITEM 1.  BUSINESS  \n\t\t\n\n \n\n\nUnless otherwise indicated, references to \"Dorian,\" the \"Company,\" \"we,\" \"our,\" \"us,\" or similar terms refer to Dorian LPG Ltd. and its subsidiaries and predecessors. The terms \"Predecessor\" and \"Predecessor Business\" refer to the owning companies of the four vessels that comprised our initial fleet, prior to their acquisition by us. We use the term \"VLGC\" to refer to very large gas carriers. We use the term \"LPG\" to refer to liquefied petroleum gas and we use the term \"cbm\" to refer to cubic meters in describing the carrying capacity of our vessels. Unless otherwise indicated, all references to \"U.S. dollars,\" \"USD,\" and \"$\" in this report are to the lawful currency of the United States of America and references to \"Norwegian Krone\" and \"NOK\" are to the lawful currency of Norway. \n\n\n \n\n\nOverview\n\n\n \n\n\nWe are a Marshall Islands corporation incorporated on July 1, 2013 and headquartered in the United States. We are focused on owning and operating VLGCs in the\n>>> New item1 new file for year LPG-18 is saved\n\n \n\n>>>Starting open files 4 for LPG\n>>> the file to be extracted is 0001596993-16-000015.txt\n\nITEM 1.  BUSINESS  \n\n\n \n\n\nUnless otherwise indicated, references to \"Dorian,\" the \"Company,\" \"we,\" \"our,\" \"us,\" or similar terms refer to Dorian LPG Ltd. and its subsidiaries and predecessors. The terms \"Predecessor\" and \"Predecessor Business\" refer to the owning companies of the four vessels that comprised our initial fleet (hereinafter referred to as our \"Initial Fleet\"), prior to their acquisition by us.  We use the term \"VLGC\" to refer to very large gas carriers and the term “PGC” to refer to pressurized gas carriers. We use the term \"LPG\" to refer to liquefied petroleum gas and we use the term \"cbm\" to refer to cubic meters in describing the carrying capacity of our vessels. Unless otherwise indicated, all references to \"U.S. dollars,\" \"USD,\" \"dollars,\" \"U.S.$,\" and \"$\" in this report are to the lawful currency of the United States of America and references to \"Norwegian Kroner\" and \"NOK\" are to the lawful currency of Norway. Unless stated otherwise, the information below gives ef\n>>> New item1 new file for year LPG-16 is saved\n\n \n\n>>>Starting open files 5 for LPG\n>>> the file to be extracted is 0000919574-15-004764.txt\n\nITEM 1.\nBUSINESS\nUnless otherwise indicated, references to \"Dorian,\" the \"Company,\" \"we,\" \"our,\" \"us,\" or similar terms refer to Dorian LPG Ltd. and its subsidiaries and predecessors. The terms \"Predecessor\" and \"Predecessor Business\" refer to the owning companies of the four vessels (hereinafter referred to as our \"Initial Fleet\"), as defined below, prior to their acquisition by us. We use the term \"VLGC\" to refer to very large gas carriers and the term \"PGC\" to refer to pressurized gas carriers. We use the term \"LPG\" to refer to liquefied petroleum gas and we use the term \"cbm\" to refer to cubic meters in describing the carrying capacity of our vessels. References in this report to \"Shell,\" \"Statoil,\" and \"Petredec\" refer to Royal Dutch Shell plc, Statoil ASA and Petredec Limited, respectively, and certain of each of their subsidiaries that are our customers. Unless otherwise indicated, all references to \"U.S. dollars,\" \"USD,\" \"dollars,\" \"U.S.$,\" and \"$\" in this report are to the law\n>>> New item1 new file for year LPG-15 is saved\n\nLPG's folder has been deleted!\n>>> Got 0 for NOMD\n>>> No 10k files for this company!\n>>> Got 0 for ARGX\n>>> No 10k files for this company!\n>>> Got 4 for ATH\n>>> Created new folder for ATH\n>>> Start extracting item1 sections for ATH\n \n\n>>>Starting open files 1 for ATH\n>>> the file to be extracted is 0001527469-19-000007.txt\n\n>Item 1. Business–Regulation–United States–Insurance Holding Company Regulation.AHL may in the future incur indebtedness in order to pay dividends to shareholders. If AHL did determine to incur additional indebtedness in order to pay dividends, such dividends would be subject to the terms of AHL’s existing indebtedness as well as any credit agreement that AHL may enter into in the future. AHL does not currently anticipate paying any regular cash dividends on its common shares. Any decision to declare and pay dividends in the future will be made at the discretion of AHL’s board of directors and will depend on, among other things, AHL’s results of operations, financial condition, cash requirements, excess capital position, alternative uses of capital, contractual restrictions and other factors that AHL’s board of directors may deem relevant. Therefore, any return on investment in AHL’s common stock may be solely dependent upon the appreciation of the price of AHL’s common stock on the op\n>>> New item1 new file for year ATH-19 is saved\n\n \n\n>>>Starting open files 2 for ATH\n>>> the file to be extracted is 0001527469-18-000011.txt\n\n>Item 1. Business–Regulation–United States–Insurance Holding Company Regulation.68Table of ContentsItem 1A.    Risk FactorsAHL may in the future incur indebtedness in order to pay dividends to shareholders. If AHL did determine to incur additional indebtedness in order to pay dividends, such dividends would be subject to the terms of AHL’s existing indebtedness as well as any credit agreement that AHL may enter into in the future. AHL does not currently anticipate paying any regular cash dividends on its common shares. Any decision to declare and pay dividends in the future will be made at the discretion of AHL’s board of directors and will depend on, among other things, AHL’s results of operations, financial condition, cash requirements, excess capital position, alternative uses of capital, contractual restrictions and other factors that AHL’s board of directors may deem relevant. Therefore, any return on investment in AHL’s common stock may be solely dependent upon the appreciation o\n>>> New item1 new file for year ATH-18 is saved\n\n \n\n>>>Starting open files 3 for ATH\n>>> the file to be extracted is 0001527469-20-000007.txt\n\n>Item 1. Business–Regulation–United States–Insurance Holding Company Regulation.Dividends by AHL are also subject to restrictions included within the Credit Facility and may be subject to restrictions included in any indebtedness or credit agreement that AHL enters into in the future. AHL does not currently anticipate paying any regular cash dividends on its common shares. Any decision to declare and pay dividends in the future will be made at the discretion of AHL’s board of directors and will depend on, among other things, AHL’s results of operations, financial condition, cash requirements, excess capital position, alternative uses of capital, contractual restrictions and other factors that AHL’s board of directors may deem relevant. Therefore, any return on investment in AHL’s common stock may be solely dependent upon the appreciation of the price of AHL’s common stock on the open market, which may not occur.Future sales of common shares by existing shareholders could cause our shar\n>>> New item1 new file for year ATH-20 is saved\n\n \n\n>>>Starting open files 4 for ATH\n>>> the file to be extracted is 0001527469-17-000011.txt\n\n>Item 1. Business. AHL may in the future incur indebtedness in order to pay dividends to shareholders. If AHL did determine to incur additional indebtedness in order to pay dividends, such dividends would be subject to the terms of AHL’s existing indebtedness as well as any credit agreement that AHL may enter into in the future. AHL does not currently anticipate paying any regular cash dividends on its common shares. Any decision to declare and pay dividends in the future will be made at the discretion of AHL’s board of directors and will depend on, among other things, AHL’s results of operations, financial condition, cash requirements, contractual restrictions and other factors that AHL’s board of directors may deem relevant. Therefore, any return on investment in AHL’s common stock may be solely dependent upon the appreciation of the price of AHL’s common stock on the open market, which may not occur.79Table of ContentsItem 1A.    Risk FactorsFulfilling our obligations with respect t\n>>> New item1 new file for year ATH-17 is saved\n\nATH's folder has been deleted!\n>>> Got 0 for MTP\n>>> No 10k files for this company!\n>>> Got 0 for NXXYF\n>>> No 10k files for this company!\n>>> Got 0 for MTFB\n>>> No 10k files for this company!\n>>> Got 0 for BPTS\n>>> No 10k files for this company!\n>>> Got 0 for WKEY\n>>> No 10k files for this company!\n>>> Got 3 for MREO\n>>> MREO folder is already exists.\n>>> Start extracting item1 sections for MREO\n \n\n>>>Starting open files 1 for MREO\n>>> the file to be extracted is 0001041609-11-000006.txt\n\n>Item 1.        Description of Business\n5\n\nItem 1A.     Risk Factors\n9\n\n\n>>> New item1 new file for year MREO-11 is saved\n\n \n\n>>>Starting open files 2 for MREO\n>>> the file to be extracted is 0001041609-09-000003.txt\n\n>Item 1.        Description of Business\n5\n\nItem 1A.     Risk Factors\n8\n\n\n>>> New item1 new file for year MREO-09 is saved\n\n \n\n>>>Starting open files 3 for MREO\n>>> the file to be extracted is 0001041609-10-000003.txt\n\n>Item 1.        Description of Business\n5\n\nItem 1A.     Risk Factors\n9\n\n\n>>> New item1 new file for year MREO-10 is saved\n\nMREO's folder has been deleted!\n>>> Got 0 for BORR\n>>> No 10k files for this company!\n>>> Got 0 for GMVD\n>>> No 10k files for this company!\n>>> Got 0 for ASLN\n>>> No 10k files for this company!\n>>> Got 0 for VIST\n>>> No 10k files for this company!\n>>> Got 0 for VVCIF\n>>> No 10k files for this company!\n>>> Got 2 for NVT\n>>> NVT folder is already exists.\n>>> Start extracting item1 sections for NVT\n \n\n>>>Starting open files 1 for NVT\n>>> the file to be extracted is 0001720635-20-000009.txt\n\nITEM 1.    BUSINESSGENERALnVent Electric plc is a leading global provider of electrical connection and protection solutions. We believe our inventive electrical solutions enable safer systems and ensure a more secure world. We design, manufacture, market, install, and service high performance products and solutions that connect and protect some of the world’s most sensitive equipment, buildings, and critical processes. We offer a comprehensive range of enclosures, electrical fastening solutions, and thermal management solutions across industry-leading brands that are recognized globally for quality, reliability, and innovation. Our broad range of products and solutions connect and protect our customers’ mission-critical equipment from hazardous conditions, improving their utilization, lowering costs, and minimizing downtime. The cost of our products typically represents a small proportion of the total cost of our customers’ end systems. We also are a small cost relative to the potentia\n>>> New item1 new file for year NVT-20 is saved\n\n \n\n>>>Starting open files 2 for NVT\n>>> the file to be extracted is 0001720635-19-000008.txt\n\nITEM 1.    BUSINESSGENERALnVent Electric plc is a leading global provider of electrical connection and protection solutions. We believe our inventive electrical solutions enable safer systems and ensure a more secure world. We design, manufacture, market, install, and service high performance products and solutions that connect and protect some of the world’s most sensitive equipment, buildings, and critical processes. We offer a comprehensive range of enclosures, electrical connections and fastening, and thermal management solutions across industry-leading brands that are recognized globally for quality, reliability, and innovation. Our broad range of products and solutions connect and protect our customers’ mission-critical equipment from hazardous conditions, improving their utilization, lowering costs, and minimizing downtime. The cost of our products typically represents a small proportion of the total cost of our customers’ end systems as well as the potential cost of failure tha\n>>> New item1 new file for year NVT-19 is saved\n\nNVT's folder has been deleted!\n>>> Got 0 for GRIN\n>>> No 10k files for this company!\n>>> Got 0 for NMCI\n>>> No 10k files for this company!\n>>> Got 0 for CSTPF\n>>> No 10k files for this company!\n>>> Got 2 for ACA\n>>> Created new folder for ACA\n>>> Start extracting item1 sections for ACA\n \n\n>>>Starting open files 1 for ACA\n>>> the file to be extracted is 0001739445-19-000020.txt\n\n>Item 1. Business.General Description of Business.  Arcosa, Inc. and its consolidated subsidiaries, (“Arcosa,” “Company,” “we,” or “our”) headquartered in Dallas, Texas, is a provider of infrastructure-related products and solutions. We provide critical products for a broad spectrum of markets throughout construction, energy, and transportation. We own businesses with well-established positions in attractive markets with favorable long-term demand drivers, which should provide us with compelling organic and acquisition opportunities. Arcosa is a Delaware corporation and was incorporated in 2018 in connection with the separation of Arcosa from Trinity Industries, Inc. (“Trinity” or “Former Parent”) on November 1, 2018 as an independent, publicly-traded company, listed on the New York Stock Exchange (the “Separation”). At the time of the Separation, Arcosa consisted of certain of Trinity’s former construction products, energy equipment, and transportation products businesses. The Separat\n>>> New item1 new file for year ACA-19 is saved\n\n \n\n>>>Starting open files 2 for ACA\n>>> the file to be extracted is 0001739445-20-000026.txt\n\n>Item 1. Business.General Description of Business. Arcosa, Inc. and its consolidated subsidiaries, (“Arcosa,” “Company,” “we,” or “our”) headquartered in Dallas, Texas, is a provider of infrastructure-related products and solutions with leading brands serving construction, energy, and transportation markets in North America. Our individual businesses have built reputations for quality, service, and operational excellence over decades. Arcosa serves a broad spectrum of infrastructure-related markets and is strategically focused on driving organic and disciplined acquisition growth to capitalize on the fragmented nature of many of the industries in which we operate. With Arcosa’s current platform of businesses and additional growth opportunities, we are well- aligned with key market trends, such as the replacement and growth of aging transportation and energy infrastructure, the continued shift to renewable power generation, and the expansion of downstream energy infrastructure.We are un\n>>> New item1 new file for year ACA-20 is saved\n\nACA's folder has been deleted!\n>>> Got 0 for CTRM\n>>> No 10k files for this company!\n>>> Got 0 for BBUS\n>>> No 10k files for this company!\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cusip</th>\n      <th>tic</th>\n      <th>ticker</th>\n      <th>extraction_info</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>155965</th>\n      <td>04522R101</td>\n      <td>ASLN</td>\n      <td>ASLN</td>\n      <td>(0, 0, 0, [])</td>\n    </tr>\n    <tr>\n      <th>155968</th>\n      <td>92837L109</td>\n      <td>VIST</td>\n      <td>VIST</td>\n      <td>(0, 0, 0, [])</td>\n    </tr>\n    <tr>\n      <th>155970</th>\n      <td>92845J104</td>\n      <td>VVCIF</td>\n      <td>VVCIF</td>\n      <td>(0, 0, 0, [])</td>\n    </tr>\n    <tr>\n      <th>155974</th>\n      <td>G6700G107</td>\n      <td>NVT</td>\n      <td>NVT</td>\n      <td>(2, 2, 0, [])</td>\n    </tr>\n    <tr>\n      <th>155981</th>\n      <td>Y28895103</td>\n      <td>GRIN</td>\n      <td>GRIN</td>\n      <td>(0, 0, 0, [])</td>\n    </tr>\n    <tr>\n      <th>155985</th>\n      <td>Y62151108</td>\n      <td>NMCI</td>\n      <td>NMCI</td>\n      <td>(0, 0, 0, [])</td>\n    </tr>\n    <tr>\n      <th>155987</th>\n      <td>04274P105</td>\n      <td>CSTPF</td>\n      <td>CSTPF</td>\n      <td>(0, 0, 0, [])</td>\n    </tr>\n    <tr>\n      <th>155988</th>\n      <td>039653100</td>\n      <td>ACA</td>\n      <td>ACA</td>\n      <td>(2, 2, 0, [])</td>\n    </tr>\n    <tr>\n      <th>155994</th>\n      <td>Y1146L109</td>\n      <td>CTRM</td>\n      <td>CTRM</td>\n      <td>(0, 0, 0, [])</td>\n    </tr>\n    <tr>\n      <th>155996</th>\n      <td>46641Q399</td>\n      <td>BBUS</td>\n      <td>BBUS</td>\n      <td>(0, 0, 0, [])</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            cusip    tic ticker extraction_info\n155965  04522R101   ASLN   ASLN   (0, 0, 0, [])\n155968  92837L109   VIST   VIST   (0, 0, 0, [])\n155970  92845J104  VVCIF  VVCIF   (0, 0, 0, [])\n155974  G6700G107    NVT    NVT   (2, 2, 0, [])\n155981  Y28895103   GRIN   GRIN   (0, 0, 0, [])\n155985  Y62151108   NMCI   NMCI   (0, 0, 0, [])\n155987  04274P105  CSTPF  CSTPF   (0, 0, 0, [])\n155988  039653100    ACA    ACA   (2, 2, 0, [])\n155994  Y1146L109   CTRM   CTRM   (0, 0, 0, [])\n155996  46641Q399   BBUS   BBUS   (0, 0, 0, [])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extraction function apply to each row of the company list dataframe\n",
    "df_44['extraction_info'] = df_44['ticker'].apply(lambda x: download_to_item1(x))\n",
    "df_44.to_csv(\"/home/hongzhuoqiao/10K_Projects/sec_filings/result_44.csv\")\n",
    "df_44.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " 10k_Similarity.ipynb",
   "provenance": [
    {
     "file_id": "1ix10DxckBK24AK1hRVRV_TZsRYuKIM87",
     "timestamp": 1581474382432
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}